server:
  name: YA_MCPServer_KnowledgeAgent
  name_zh: 个性化知识管理智能体
  author: kislate
  description: A personalized knowledge management agent with RAG-based intelligent Q&A.
  description_zh: 基于 RAG 的个性化知识管理智能体，支持知识存储、语义检索和智能问答。
  version: 0.1.0

transport:
  type: "stdio"
  # host: "127.0.0.1"
  # port: 12345

logging:
  console:
    enabled: true
    level: "DEBUG"
  file:
    enabled: true
    level: "DEBUG"
    path: "logs/%Y-%m-%d_%H-%M-%S.log"
    rotation: "10 MB"
    retention: "7 days"
    compression: "zip"

# LLM 配置
llm:
  default_provider: "deepseek"   # 默认 provider，可改为 openai / siliconflow
  deepseek:
    base_url: "https://api.deepseek.com"
    model: "deepseek-chat"
    max_tokens: 1024       # RAG 问答 1024 够用，减少等待时间
    temperature: 0.7
  openai:
    base_url: "https://api.openai.com/v1"
    model: "gpt-4o-mini"
    max_tokens: 1024
    temperature: 0.7
  siliconflow:
    base_url: "https://api.siliconflow.cn/v1"
    model: "deepseek-ai/DeepSeek-V3"  # 速度比 deepseek.com 快，可设为 default_provider
    max_tokens: 1024
    temperature: 0.7

# 翻译配置
translate:
  use_llm: true                          # true=优先用 LLM 翻译，false=仅用 MyMemory
  llm_provider: "deepseek"               # 翻译用的 LLM provider
  mymemory_fallback: true                # LLM 失败时降级到 MyMemory
  base_url: "https://api.mymemory.translated.net"

# ===== 知识管理配置 =====
knowledge:
  chromadb:
    persist_directory: "./data/chromadb"
    collection_name: "knowledge_base"
  # Embedding 配置（使用硅基流动 SiliconFlow 的 OpenAI 兼容接口）
  embedding:
    provider: "openai"  # 使用 OpenAI 兼容接口
    base_url: "https://api.siliconflow.cn/v1"
    model: "BAAI/bge-m3"  # 免费，中英文效果好，1024维
  chunking:
    chunk_size: 1000    # 每块最大字符数（bge-m3 支持 8192 token，1000字绰绰有余）
    chunk_overlap: 100
  retrieval:
    top_k: 5
    min_relevance: 0.3
  export:
    output_dir: "./data/exports"

# RAG 设置
rag:
  web_fallback:
    enabled: true           # 本地高相关结果不足时自动补充网络搜索
    min_local_results: 1    # 本地「高相关」结果少于该数量时触发 web 搜索
    web_results: 3          # fallback 搜索结果数
  ai_answer:
    enabled: true                 # 知识不足时仍由 AI 综合生成答案（默认开启，永不返回空答案）
    high_relevance_threshold: 0.6 # 相关度超过此值才视为「高相关」；低于时触发 web 补充
    allow_llm_knowledge: true     # 允许 AI 结合自身通用知识补充（非纯检索模式）